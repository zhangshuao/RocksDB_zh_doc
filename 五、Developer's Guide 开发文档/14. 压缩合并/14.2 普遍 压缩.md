# 普遍压缩

通用压缩样式是一种压缩样式，针对需要较低的写放大、交换读放大和空间放大的用例。

## 概念基础

正如多位作者和系统介绍的，LSM-tree压缩策略主要有两种类型:

* 分层压缩，作为RocksDB中的默认压缩样式
* 另一种压缩策略，有时称为"大小分层"[1] 或 "分层"[2]。

## 概述和基本思想

这两种策略之间的关键区别在于，水平压缩倾向于积极地将较小的排序运行合并为较大的排序运行，而 "分层" 则等待几个大小相似的排序运行并将它们合并在一起。

一般认为，第二种策略提供了更好的写放大与更差的读放大[2][3]。
一种直观的方法是: 
在分层存储中，每次压缩更新时，更新都倾向于从较小的排序运行移动到较大的排序运行。每次压缩都可能使更新指数级地接近最终排序的运行，即最大的运行。
然而，在分层压缩中，更新被压缩为更大的排序运行的一部分，其中合并了更小的排序运行，而不是更小的排序运行的一部分。
因此，在大多数情况下，一个更新被压缩，它不会被移动到一个更大的排序运行中，所以它不会在最终的最大运行中取得多大的进展

"分层"压缩的好处并非没有缺点。更糟糕的情况是，已排序的运行数远远高于水平压缩。
在读取期间，它可能会导致更高的I/O成本和/或更高的CPU成本。
压缩调度的惰性也使得压缩流量更加尖峰，排序运行的数量随时间变化很大，因此性能差异很大。

不过，RocksDB在"分层"家族中提供了一个通用的压缩。如果分层压缩不能处理所需的写速率，用户可以尝试这种压缩样式。

[1] 这个词是卡桑德拉使用的。查阅 他们的 doc. （ https://docs.datastax.com/en/cassandra/3.0/cassandra/operations/opsConfigureCompaction.html ）
[2] "猴子:最佳导航键值存储"，载于ACM SIGMOD数据管理国际会议，2017。
[3] https://smalldatum.blogspot.com/2018/08/name-that-compaction-algorithm.html

## 限制

当使用这种压缩样式时，所有的SST文件都被组织为覆盖整个键范围的排序运行。一个排序的运行包括在一个时间范围内生成的数据。
不同排序的运行不会在它们的时间范围上重叠。压缩只能发生在相邻时间范围的两个或多个排序运行之间。
输出是一个单独的排序运行，其时间范围是输入排序运行的组合。在任何压缩之后，排序运行的条件在它们的时间范围上永远不会重叠，这仍然成立。
排序后的运行可以实现为一个L0文件，或一个"级别"，其中数据存储为键范围分区文件。

压缩风格的基本思想: 一个阈值的数量排序运行N,我们只有开始压实当数排序运行达到N. 当它发生时,我们尽量选择文件紧凑,这样排序的运行数量减少了以最经济的方式: 
1.它从最小的文件开始; 
2. 如果文件大小不大于现有的压缩大小，则会包含一个文件。该策略假设并尝试维护排序后的运行包含的最新数据小于包含旧数据的运行。

### 两倍大小的问题

在通用样式的压缩中，有时需要完全压缩。在本例中，输出数据大小与输入大小类似。
在压缩期间，需要同时保存输入文件和输出文件，因此DB的磁盘空间使用量将临时增加一倍。
确保有足够的空间进行充分的压缩。

### 如果num_levels=1，则DB(列族)大小

当使用通用压缩时，如果num_levels = 1, DB(或者更精确地说，列族)的所有数据有时会压缩到一个SST文件中。
一个SST文件的大小是有限制的。在RocksDB中，一个块不能超过4GB(允许大小为uint32)。如果单个SST文件太大，索引块可能会超过限制。
索引块的大小取决于您的数据。在我们的一个用例中，当DB使用4K数据块大小增长到250GB左右时，我们将观察DB以达到限制。
要减轻这种限制，可以使用分区索引。

如果用户将num_levels设置为比1大得多的值，这个问题就会得到缓解。在这种情况下，较大的"文件"将放在较大的"级别"中，文件将被划分为较小的文件(更多解释见下文)。
L0->L0压缩仍然可以用于并行压缩，但是L0中的文件很可能要小得多。 
 
## 数据布局和放置
 
### 有序的运行

如上所述，数据被组织为排序的运行。排序后的运行由其中数据的更新时间安排，并以L0文件或整个"级别"的形式存储。

下面是一个典型文件布局的例子:

    Level 0: File0_0, File0_1, File0_2
    Level 1: (empty)
    Level 2: (empty)
    Level 3: (empty)
    Level 4: File4_0, File4_1, File4_2, File4_3
    Level 5: File5_0, File5_1, File5_2, File5_3, File5_4, File5_5, File5_6, File5_7

与较小数字的级别相比，较大数字的级别包含较旧的排序运行。
在本例中，有5个排序的运行: 级别0、级别4和级别5中的3个文件。级别5是最老的排序运行，级别4是最新的，级别0文件是最新的。

### 压实输出的放置

压缩总是为具有连续时间范围的排序运行调度，输出总是另一个排序运行。
我们总是将压缩输出放在尽可能高的级别，遵循旧数据在具有较大数量的级别上的规则。

使用上面显示的相同示例。我们有以下排序运行:

    File0_0
    File0_1
    File0_2
    Level 4: File4_0, File4_1, File4_2, File4_3
    Level 5: File5_0, File5_1, File5_2, File5_3, File5_4, File5_5, File5_6, File5_7

如果我们压缩所有数据，排序后的输出运行将放在第5级。所以它就变成:

    Level 5: File5_0', File5_1', File5_2', File5_3', File5_4', File5_5', File5_6', File5_7'

从这个状态开始，让我们看看如何放置输出排序运行，如果我们调度不同的压缩:

如果压缩File0_1、File0_2和第4级，排序后的输出运行将放在第4级。

    Level 0: File0_0
    Level 1: (empty)
    Level 2: (empty)
    Level 3: (empty)
    Level 4: File4_0', File4_1', File4_2', File4_3'
    Level 5: File5_0, File5_1, File5_2, File5_3, File5_4, File5_5, File5_6, File5_7

如果压缩File0_0、File0_1和File0_2，则排序后的输出运行将放在第3级。

    Level 0: (empty)
    Level 1: (empty)
    Level 2: (empty)
    Level 3: File3_0, File3_1, File3_2
    Level 4: File4_0, File4_1, File4_2, File4_3
    Level 5: File5_0, File5_1, File5_2, File5_3, File5_4, File5_5, File5_6, File5_7

如果压缩File0_0和File0_1，排序后的输出运行仍然位于0级。

    Level 0: File0_0', File0_2
    Level 1: (empty)
    Level 2: (empty)
    Level 3: (empty)
    Level 4: File4_0, File4_1, File4_2, File4_3
    Level 5: File5_0, File5_1, File5_2, File5_3, File5_4, File5_5, File5_6, File5_7

### 特殊情况options.num_levels = 1

如果options.num_levels=1，我们仍然遵循相同的放置规则。这意味着所有的文件将被放置在0级以下，并且每个文件都是经过排序的运行。
该行为将与初始通用压缩相同，因此可以将其用作向后兼容模式。

## 选择压缩算法

假设我们已经排序了

    R1, R2, R3, ..., Rn

其中R1包含数据库最新更新的数据，Rn包含数据库最老更新的数据。注意，它是按已排序运行内数据的年龄排序的，而不是按已排序运行本身排序的。
根据这个排序顺序，在压缩之后，已排序的输出运行总是放在输入所在的位置。

如何获得所有的压缩:

**Precondition: n >= options.level0_file_num_compaction_trigger**

除非排序运行的数量达到这个阈值，否则根本不会触发压缩。

(注意，虽然选项名使用 word "file"，但是由于历史原因，触发器用于"已排序运行"。
对于下面提到的所有选项的名称，"file"也意味着出于相同的原因排序后运行。

如果满足先决条件，则有三个条件。每一个都可以触发压缩:

**1.由空间放大触发的压缩**

如果估计的大小放大比options.compaction_options_universal.max_size_amplification_percent / 100大，则所有文件将压缩为一个排序的运行。

尺寸放大比的估算方法如下:

    size amplification ratio = (size(R1) + size(R2) + ... size(Rn-1)) / size(Rn)

请注意，Rn的尺寸不包括在内，这意味着0是完美的尺寸放大，100意味着DB尺寸是实时数据空间的两倍，200意味着三倍。

我们以这种方式估计大小放大的原因是: 
在一个稳定大小的DB中，传入的删除速率应该与插入速率相似，这意味着除了Rn之外的任何排序的运行都应该包含类似的插入和删除次数。
应用R1、R2后…对于Rn，它们的大小效应会相互抵消，所以输出也应该是Rn的大小，也就是实时数据的大小，作为大小放大的基础。

如果options.compaction_options_universal. max_size_fication_percent = 25，这意味着我们将保持DB总空间小于活动数据总大小的125%。
让我们在一个例子中使用这个值。假设压缩仅由空间放大触发，选项。level0_file_num_compaction_trigger = 1，每次mem表刷新后的文件大小总是1，压缩后的大小总是等于总输入大小。
在两次刷新之后，我们有两个文件大小为1，而1/1 > 25%，所以我们需要做一个完整的压缩:

    1 1  =>  2

我们又一次刷新了mem表

    1 2   =>  3

这再次触发了一个完整的压缩，因为1/2 > 25%。以同样的方式:

    1 3  =>  4

但在另一次刷新之后，不会触发压缩:

    1 4

因为1/4 <= 25%另一个mem表刷新将触发另一个压缩:

    1 1 4  =>  6

因为(1+1)/ 4 > 25%
一直是这样的:

    1
    1 1  =>  2
    1 2  =>  3
    1 3  =>  4
    1 4
    1 1 4  =>  6
    1 6
    1 1 6  =>  8
    1 8
    1 1 8
    1 1 1 8  =>  11
    1 11
    1 1 11
    1 1 1 11  =>  14
    1 14
    1 1 14
    1 1 1 14
    1 1 1 1 14  =>  18

**2.由单个粒度比触发的压缩**

我们计算大小比触发器的值为

    size_ratio_trigger = 100 + options.compaction_options_universal.size_ratio / 100

通常 options.compaction_options_universal.size_ratio 接近于0，所以size ratio触发器接近于1。
    
我们从R1开始，如果size(R2) / size(R1) <= size ratio trigger，则(R1, R2)有资格被压缩在一起。
我们从这里继续，来决定R3是否也可以相加。如果size(R3) / size(R1 + R2) <= size ratio trigger，则包含(R1, R2, R3)。然后我们对F4做同样的处理。
我们一直将现有的总大小与下一个排序的运行进行比较，直到size ratio触发器条件不再适用为止。

这里有一个例子，使它更容易理解。假设options.compaction_options_universal.size_ratio = 0，总mem表刷新大小总是1，压缩大小总是等于总输入大小，压缩仅由空间放大和选项触发。
level0_file_num_compaction_trigger = 5。从一个空DB开始，在5个mem表刷新之后，我们有5个文件大小为1，这触发了对所有文件的压缩，因为1/1 <= 1,1 /(1+1)<= 1,1 /(1+1+1)<=1和1/(1+1+1)<=1和1/(1+1+1)<=1:

    1 1 1 1 1  =>  5

在4个mem表刷新之后，使它再次变成5个文件。前4个文件符合合并条件:1/1 <= 1,1 /(1+1)<= 1,1 /(1+1+1)<=1。5/(1+1+1+1) > 1:

    1 1 1 1 5  => 4 5

他们这样持续了好几轮:

    1 1 1 1 1  =>  5
    1 5  (no compaction triggered)
    1 1 5  (no compaction triggered)
    1 1 1 5  (no compaction triggered)
    1 1 1 1 5  => 4 5
    1 4 5  (no compaction triggered)
    1 1 4 5  (no compaction triggered)
    1 1 1 4 5 => 3 4 5
    1 3 4 5  (no compaction triggered)
    1 1 3 4 5 => 2 3 4 5

再冲一次水，就像

    1 2 3 4 5

没有触发压缩，所以我们保持压缩。只有当再次刷新时，所有文件才有资格压缩在一起:

    1 1 2 3 4 5 => 16

因为1/1 < = 1,2 /(1 + 1)< = 1,3 /(1 + 1 + 2)< = 1,4 /(1 + 1 + 2 + 3)< = 1和5 / (1 + 1 + 2 + 3 + 4)< = 1。然后我们继续:
    
    1 16  (no compaction triggered)
    1 1 16  (no compaction triggered)
    1 1 1 16  (no compaction triggered)
    1 1 1 1 16  => 4 16
    1 4 16  (no compaction triggered)
    1 1 4 16  (no compaction triggered)
    1 1 1 4 16 => 3 4 16
    1 3 4 16  (no compaction triggered)
    1 1 3 4 16 => 2 3 4 16
    1 2 3 4 16  (no compaction triggered)
    1 1 2 3 4 16 => 11 16

只有当输入排序后的运行数至少是options.compaction_options_universal.min_merge_width时才会触发压缩，
作为输入的排序后的运行数的上限不超过options.compaction_options_universal.max_merge_width。


**3.由已排序的运行数触发的压缩**

如果每次我们尝试调度一个压缩，1和2都没有被触发，我们将尝试压缩R1、R2中任何排序的运行…，以便在压缩之后，排序后的运行总数不大于options.level0_file_num_compaction_trigger。
如果我们需要压缩比options.compaction_options_universal.max_merge_width更多的排序运行数，我们将其限制为options.compaction_options_universal.max_merge_width。

我下面提到的"尝试调度"将在刷新memtable后发生，完成压缩。有时会安排重复的尝试。

请参阅通用样式压缩示例，作为常见设置的输出排序运行大小的示例。

如果有选项，则可以进行并行压缩。max_background_compactions > 1。
与所有其他压缩样式相同，并行压缩将不能在相同的排序运行上工作。

### 子压缩

在通用压缩中支持子压缩。如果压缩的输出级别不是"级别"0，我们将尝试对输入进行范围分区，并使用选项的线程数。max_sub紧凑化为并行压缩。
这将有助于解决通用压实法的全压实耗时过长的问题。

### 选项来调整

以下是影响通用压缩的选项:

* options.compaction_options_universal: 上述各项选择
* options.level0_file_num_compaction_trigger: 任何压缩的触发条件。这也意味着在所有的压缩完成之后，排序后的运行数将在options.level0_file_num_compaction_trigger+1下
* options.level0_slowdown_writes_trigger: 如果排序后的运行次数超过此值，则会人为地降低写操作的速度。
* options.level0_stop_writes_trigger: 如果已排序的运行数超过此值，则写操作将停止，直到压缩完成且已排序的运行数低于此阈值为止。
* options.num_levels: 如果该值为1，所有排序的运行将存储为0级文件。否则，我们将尽量填充非零级别。num_levels越大，在0级上拥有大文件的可能性就越小。
* options.target_file_size_base: 有效的选择。num_levels > 1。级别0以外的文件将被削减到不大于此阈值的文件大小。
* options.target_file_size_multiplier: 它是有效的，但是我们不知道如何在通用压缩中使用这个选项。所以我们不建议你调它。
 
以下选项不影响通用压缩:

* options.max_bytes_for_level_base: 仅用于基于级别的压缩
* options.level_compaction_dynamic_level_bytes: 仅用于基于级别的压缩
* options.max_bytes_for_level_multiplier 和 options.max_bytes_for_level_multiplier_additional: 仅用于基于级别的压缩
* options.expanded_compaction_factor: 仅用于基于级别的压缩
* options.source_compaction_factor: 仅用于基于级别的压缩
* options.max_grandparent_overlap_factor: 仅用于基于级别的压缩
* options.soft_rate_limit 和 options.hard_rate_limit: 弃用
* options.hard_pending_compaction_bytes_limit: 仅用于基于级别的压缩
* options.compaction_pri: 仅支持基于级别的压缩

## 估计写放大

估计写放大将非常有助于用户调优通用压缩。然而，这很难做到。由于一般压实总是在局部进行优化决策，所以lsm树的形状很难预测。
您可以从上面提到的例子中看到它。我们仍然没有一个好的数学模型来预测写放大。

这里有一个不太好的估计。

估计基于简单,每次更新压实,输出的大小排序是翻倍的原始运行(这是一个野生的未经证实的估计),除了第一个或最后一个压实经验,类似大小的排序运行在哪里一起压缩。

举个例子，如果options.compaction_options_universal. max_size_fication_percent = 25，最后排序的运行大小为256GB，从memtable和options中清除后SST文件大小为256MB。
level0_file_num_compaction_trigger = 11。然后在一个稳定的阶段，文件大小是这样的:
    
    256MB
    256MB
    256MB
    256MB
    2GB
    4GB
    8GB
    16GB
    16GB
    16GB
    256GB
    
压缩阶段如下与它的写入放大器:

    256MB
    256MB
    256MB  (write amp 1)
    256MB
    --------
    2GB    (write amp 1)
    --------
    4GB    (write amp 1)
    --------
    8GB    (write amp 1)
    --------
    16GB
    16GB    (write amp 1)
    16GB
    --------
    256GB   (write amp 4)

所以总的写放大器估计是9。

这里是如何写放大估计:

compaction_options_universal. max_size_magnification_percent本身总是引入写放大，它比100小得多。这个写放大估计是

WA1 = 100 / options.compaction_options_universal.max_size_amplification_percent。

如果不低于100，估计一下

WA1 = 0

估计除上次排序运行之外的其他总数据大小，如果options.compaction_options_universal.max_size_expanfication_percent < 100，则使用

S = total_size * (options.compaction_options_universal. max_size_magnification_percent /100)

否则

S = total_size

估计从memtable中刷新的SST文件大小为m，我们估计更新的最大压缩数为:

p = log(2, S/M)

建议选择。level0_file_num_compaction_trigger > p.然后我们使用以下方法估计由于单个大小比而导致的写入放大:

WA2 = p - log(2, options.level0_file_num_compaction_trigger - p)

然后总的写放大估计是WA1 + WA2。
